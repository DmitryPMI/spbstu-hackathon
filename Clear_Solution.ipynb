{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Flatten\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Roma_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(list(data[data[\"sentiment\"] == \"IRR\"].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[\"tweet\"].values[:1700]\n",
    "test = data[\"tweet\"].values[1701:]\n",
    "y = data[\"sentiment\"].values\n",
    "train_cross = data[\"tweet\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y).astype('int32')\n",
    "Y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y[:1700]\n",
    "y_test = Y[1701:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         analyzer='word',\n",
    "                         max_df=0.9, \n",
    "                         min_df=5\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = tf_idf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_idf_vec = tf_idf_model.transform(train)\n",
    "test_tf_idf_vec = tf_idf_model.transform(test)\n",
    "train_cross_vec = tf_idf_model.transform(train_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 4)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 4)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 946)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf_idf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 946)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_idf_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dense(461, input_dim=461))\n",
    "model.add(Dense(256, input_dim=946, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "#model.add(Dense(256, activation=\"relu\"))\n",
    "#model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(4,  activation=\"softmax\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1700 samples, validate on 182 samples\n",
      "Epoch 1/50\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3978 - fmeasure: 0.4589 - val_loss: 0.3284 - val_fmeasure: 0.6612\n",
      "Epoch 2/50\n",
      "1700/1700 [==============================] - 1s 551us/step - loss: 0.2786 - fmeasure: 0.7578 - val_loss: 0.3398 - val_fmeasure: 0.6676\n",
      "Epoch 3/50\n",
      "1700/1700 [==============================] - 1s 539us/step - loss: 0.1987 - fmeasure: 0.8264 - val_loss: 0.3612 - val_fmeasure: 0.6739\n",
      "Epoch 4/50\n",
      "1700/1700 [==============================] - 1s 550us/step - loss: 0.1297 - fmeasure: 0.8944 - val_loss: 0.4502 - val_fmeasure: 0.6798\n",
      "Epoch 5/50\n",
      "1700/1700 [==============================] - 1s 548us/step - loss: 0.0823 - fmeasure: 0.9451 - val_loss: 0.4916 - val_fmeasure: 0.6677\n",
      "Epoch 6/50\n",
      "1700/1700 [==============================] - 1s 546us/step - loss: 0.0533 - fmeasure: 0.9702 - val_loss: 0.5875 - val_fmeasure: 0.6599\n",
      "Epoch 7/50\n",
      "1700/1700 [==============================] - 1s 600us/step - loss: 0.0425 - fmeasure: 0.9716 - val_loss: 0.6004 - val_fmeasure: 0.6819\n",
      "Epoch 8/50\n",
      "1700/1700 [==============================] - 1s 578us/step - loss: 0.0399 - fmeasure: 0.9744 - val_loss: 0.6315 - val_fmeasure: 0.6741\n",
      "Epoch 9/50\n",
      "1700/1700 [==============================] - 1s 582us/step - loss: 0.0297 - fmeasure: 0.9782 - val_loss: 0.6765 - val_fmeasure: 0.6766\n",
      "Epoch 10/50\n",
      "1700/1700 [==============================] - 1s 580us/step - loss: 0.0303 - fmeasure: 0.9776 - val_loss: 0.7093 - val_fmeasure: 0.6758\n",
      "Epoch 11/50\n",
      "1700/1700 [==============================] - 1s 623us/step - loss: 0.0288 - fmeasure: 0.9800 - val_loss: 0.6853 - val_fmeasure: 0.6595\n",
      "Epoch 12/50\n",
      "1700/1700 [==============================] - 1s 592us/step - loss: 0.0257 - fmeasure: 0.9794 - val_loss: 0.7105 - val_fmeasure: 0.6618\n",
      "Epoch 13/50\n",
      "1700/1700 [==============================] - 1s 538us/step - loss: 0.0270 - fmeasure: 0.9784 - val_loss: 0.7314 - val_fmeasure: 0.6914\n",
      "Epoch 14/50\n",
      "1700/1700 [==============================] - 1s 628us/step - loss: 0.0263 - fmeasure: 0.9776 - val_loss: 0.7221 - val_fmeasure: 0.6741\n",
      "Epoch 15/50\n",
      "1700/1700 [==============================] - 1s 680us/step - loss: 0.0251 - fmeasure: 0.9785 - val_loss: 0.7460 - val_fmeasure: 0.6832\n",
      "Epoch 16/50\n",
      "1700/1700 [==============================] - 1s 584us/step - loss: 0.0259 - fmeasure: 0.9791 - val_loss: 0.7420 - val_fmeasure: 0.6607\n",
      "Epoch 17/50\n",
      "1700/1700 [==============================] - 1s 575us/step - loss: 0.0237 - fmeasure: 0.9791 - val_loss: 0.8337 - val_fmeasure: 0.6779\n",
      "Epoch 18/50\n",
      "1700/1700 [==============================] - 1s 648us/step - loss: 0.0230 - fmeasure: 0.9785 - val_loss: 0.8554 - val_fmeasure: 0.6576\n",
      "Epoch 19/50\n",
      "1700/1700 [==============================] - 1s 523us/step - loss: 0.0239 - fmeasure: 0.9782 - val_loss: 0.7847 - val_fmeasure: 0.6679\n",
      "Epoch 20/50\n",
      "1700/1700 [==============================] - 1s 538us/step - loss: 0.0230 - fmeasure: 0.9782 - val_loss: 0.8156 - val_fmeasure: 0.6582\n",
      "Epoch 21/50\n",
      "1700/1700 [==============================] - 1s 539us/step - loss: 0.0226 - fmeasure: 0.9797 - val_loss: 0.8475 - val_fmeasure: 0.6529\n",
      "Epoch 22/50\n",
      "1700/1700 [==============================] - 1s 518us/step - loss: 0.0216 - fmeasure: 0.9797 - val_loss: 0.8673 - val_fmeasure: 0.6703\n",
      "Epoch 23/50\n",
      "1700/1700 [==============================] - 1s 623us/step - loss: 0.0209 - fmeasure: 0.9808 - val_loss: 0.8978 - val_fmeasure: 0.6770\n",
      "Epoch 24/50\n",
      "1700/1700 [==============================] - 1s 522us/step - loss: 0.0209 - fmeasure: 0.9791 - val_loss: 0.8623 - val_fmeasure: 0.6779\n",
      "Epoch 25/50\n",
      "1700/1700 [==============================] - 1s 541us/step - loss: 0.0211 - fmeasure: 0.9797 - val_loss: 0.8787 - val_fmeasure: 0.6557\n",
      "Epoch 26/50\n",
      "1700/1700 [==============================] - 1s 614us/step - loss: 0.0203 - fmeasure: 0.9788 - val_loss: 0.9158 - val_fmeasure: 0.6667\n",
      "Epoch 27/50\n",
      "1700/1700 [==============================] - 1s 573us/step - loss: 0.0202 - fmeasure: 0.9800 - val_loss: 0.9509 - val_fmeasure: 0.6523\n",
      "Epoch 28/50\n",
      "1700/1700 [==============================] - 1s 533us/step - loss: 0.0206 - fmeasure: 0.9797 - val_loss: 0.9154 - val_fmeasure: 0.6690\n",
      "Epoch 29/50\n",
      "1700/1700 [==============================] - 1s 533us/step - loss: 0.0202 - fmeasure: 0.9799 - val_loss: 0.9122 - val_fmeasure: 0.6692\n",
      "Epoch 30/50\n",
      "1700/1700 [==============================] - 1s 573us/step - loss: 0.0193 - fmeasure: 0.9805 - val_loss: 0.9303 - val_fmeasure: 0.6777\n",
      "Epoch 31/50\n",
      "1700/1700 [==============================] - 1s 626us/step - loss: 0.0195 - fmeasure: 0.9797 - val_loss: 0.9676 - val_fmeasure: 0.6868\n",
      "Epoch 32/50\n",
      "1700/1700 [==============================] - 1s 609us/step - loss: 0.0190 - fmeasure: 0.9803 - val_loss: 0.9537 - val_fmeasure: 0.6834\n",
      "Epoch 33/50\n",
      "1700/1700 [==============================] - 1s 522us/step - loss: 0.0194 - fmeasure: 0.9800 - val_loss: 0.9909 - val_fmeasure: 0.6868\n",
      "Epoch 34/50\n",
      "1700/1700 [==============================] - 1s 535us/step - loss: 0.0191 - fmeasure: 0.9817 - val_loss: 0.9903 - val_fmeasure: 0.6758\n",
      "Epoch 35/50\n",
      "1700/1700 [==============================] - 1s 536us/step - loss: 0.0192 - fmeasure: 0.9802 - val_loss: 0.9805 - val_fmeasure: 0.6838\n",
      "Epoch 36/50\n",
      "1700/1700 [==============================] - 1s 814us/step - loss: 0.0191 - fmeasure: 0.9806 - val_loss: 0.9785 - val_fmeasure: 0.6612\n",
      "Epoch 37/50\n",
      "1700/1700 [==============================] - 1s 589us/step - loss: 0.0197 - fmeasure: 0.9791 - val_loss: 1.0097 - val_fmeasure: 0.6563\n",
      "Epoch 38/50\n",
      "1700/1700 [==============================] - 1s 578us/step - loss: 0.0194 - fmeasure: 0.9796 - val_loss: 1.0563 - val_fmeasure: 0.6559\n",
      "Epoch 39/50\n",
      "1700/1700 [==============================] - 1s 576us/step - loss: 0.0186 - fmeasure: 0.9799 - val_loss: 1.0316 - val_fmeasure: 0.6703\n",
      "Epoch 40/50\n",
      "1700/1700 [==============================] - 1s 617us/step - loss: 0.0182 - fmeasure: 0.9823 - val_loss: 1.0415 - val_fmeasure: 0.6563\n",
      "Epoch 41/50\n",
      "1700/1700 [==============================] - 1s 624us/step - loss: 0.0184 - fmeasure: 0.9800 - val_loss: 1.0491 - val_fmeasure: 0.6722\n",
      "Epoch 42/50\n",
      "1700/1700 [==============================] - 1s 587us/step - loss: 0.0182 - fmeasure: 0.9809 - val_loss: 1.0559 - val_fmeasure: 0.6618\n",
      "Epoch 43/50\n",
      "1700/1700 [==============================] - 1s 683us/step - loss: 0.0182 - fmeasure: 0.9808 - val_loss: 1.1726 - val_fmeasure: 0.6559\n",
      "Epoch 44/50\n",
      "1700/1700 [==============================] - 1s 699us/step - loss: 0.0190 - fmeasure: 0.9805 - val_loss: 1.0319 - val_fmeasure: 0.6474\n",
      "Epoch 45/50\n",
      "1700/1700 [==============================] - 1s 603us/step - loss: 0.0225 - fmeasure: 0.9794 - val_loss: 0.9734 - val_fmeasure: 0.6508\n",
      "Epoch 46/50\n",
      "1700/1700 [==============================] - 1s 650us/step - loss: 0.0212 - fmeasure: 0.9782 - val_loss: 1.0318 - val_fmeasure: 0.6538\n",
      "Epoch 47/50\n",
      "1700/1700 [==============================] - 1s 639us/step - loss: 0.0227 - fmeasure: 0.9782 - val_loss: 1.0117 - val_fmeasure: 0.6451\n",
      "Epoch 48/50\n",
      "1700/1700 [==============================] - 1s 616us/step - loss: 0.0207 - fmeasure: 0.9808 - val_loss: 1.0991 - val_fmeasure: 0.6448\n",
      "Epoch 49/50\n",
      "1700/1700 [==============================] - 1s 645us/step - loss: 0.0224 - fmeasure: 0.9808 - val_loss: 1.0765 - val_fmeasure: 0.6722\n",
      "Epoch 50/50\n",
      "1700/1700 [==============================] - 1s 623us/step - loss: 0.0187 - fmeasure: 0.9796 - val_loss: 1.0592 - val_fmeasure: 0.6648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1006a2ef98>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_tf_idf_vec, y_train,  batch_size = 15, epochs=50, verbose=1, validation_data = (test_tf_idf_vec, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка результатов, метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "#model.add(Dense(461, input_dim=461))\n",
    "model1.add(Dense(512, input_dim=946, activation=\"relu\"))\n",
    "#model1.add(Dense(256, activation=\"relu\"))\n",
    "#model1.add(Dense(512, activation=\"relu\"))\n",
    "#model.add(Dense(64, activation=\"relu\"))\n",
    "model1.add(Dense(4,  activation=\"softmax\"))\n",
    "sgd = optimizers.SGD(lr=0.0005, decay=0.000001, momentum=0.9, nesterov=True)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1700 samples, validate on 182 samples\n",
      "Epoch 1/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.4005 - acc: 0.8003 - val_loss: 0.3790 - val_acc: 0.7967\n",
      "Epoch 2/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3985 - acc: 0.8056 - val_loss: 0.3774 - val_acc: 0.7953\n",
      "Epoch 3/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3963 - acc: 0.8101 - val_loss: 0.3762 - val_acc: 0.8022\n",
      "Epoch 4/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3943 - acc: 0.8056 - val_loss: 0.3743 - val_acc: 0.7953\n",
      "Epoch 5/20\n",
      "1700/1700 [==============================] - 3s 2ms/step - loss: 0.3922 - acc: 0.8107 - val_loss: 0.3728 - val_acc: 0.8077\n",
      "Epoch 6/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3900 - acc: 0.8163 - val_loss: 0.3715 - val_acc: 0.8091\n",
      "Epoch 7/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3879 - acc: 0.8138 - val_loss: 0.3698 - val_acc: 0.8132\n",
      "Epoch 8/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3857 - acc: 0.8144 - val_loss: 0.3680 - val_acc: 0.8091\n",
      "Epoch 9/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3835 - acc: 0.8250 - val_loss: 0.3663 - val_acc: 0.8091\n",
      "Epoch 10/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3811 - acc: 0.8285 - val_loss: 0.3647 - val_acc: 0.8187\n",
      "Epoch 11/20\n",
      "1700/1700 [==============================] - 3s 1ms/step - loss: 0.3787 - acc: 0.8303 - val_loss: 0.3631 - val_acc: 0.8255\n",
      "Epoch 12/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3762 - acc: 0.8300 - val_loss: 0.3612 - val_acc: 0.8310\n",
      "Epoch 13/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3737 - acc: 0.8394 - val_loss: 0.3594 - val_acc: 0.8310\n",
      "Epoch 14/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3713 - acc: 0.8399 - val_loss: 0.3576 - val_acc: 0.8393\n",
      "Epoch 15/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3687 - acc: 0.8432 - val_loss: 0.3559 - val_acc: 0.8365\n",
      "Epoch 16/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3660 - acc: 0.8482 - val_loss: 0.3540 - val_acc: 0.8434\n",
      "Epoch 17/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3636 - acc: 0.8481 - val_loss: 0.3521 - val_acc: 0.8434\n",
      "Epoch 18/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3609 - acc: 0.8481 - val_loss: 0.3507 - val_acc: 0.8434\n",
      "Epoch 19/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3582 - acc: 0.8560 - val_loss: 0.3484 - val_acc: 0.8448\n",
      "Epoch 20/20\n",
      "1700/1700 [==============================] - 2s 1ms/step - loss: 0.3554 - acc: 0.8535 - val_loss: 0.3470 - val_acc: 0.8448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1013c95eb8>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_tf_idf_vec, y_train,  batch_size = 5, epochs=20, verbose=1, validation_data = (test_tf_idf_vec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.5930716e-07 7.0942442e-06 9.9974936e-01 2.4255559e-04]\n",
      "[0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "print(model1.predict(test_tf_idf_vec)[k])\n",
    "print(y_test[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 121\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_Y = LabelEncoder().fit_transform(y)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=946, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    sgd = optimizers.SGD(lr=0.0005, decay=0.000001, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def baseline_model_1():\n",
    "    # create model\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(256, input_dim=946, activation='relu'))\n",
    "    model1.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    sgd = optimizers.SGD(lr=0.0005, decay=0.000001, momentum=0.9, nesterov=True)\n",
    "    model1.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[fmeasure, \"accuracy\"])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.37% (0.11%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, train_cross_vec, dummy_y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_measure: 76.56% (0.33%)\n"
     ]
    }
   ],
   "source": [
    "estimator1 = KerasClassifier(build_fn=baseline_model_1, epochs=50, batch_size=5, verbose=0)\n",
    "kfold1 = KFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "results1 = cross_val_score(estimator, train_cross_vec, dummy_y, cv=kfold)\n",
    "print(\"F_measure: %.2f%% (%.2f%%)\" % (results1.mean()*100, results1.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "angl_data = pd.read_csv(\"Roma_Anglichanin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = angl_data[\"tweet\"].values[:1000]\n",
    "test = angl_data[\"tweet\"].values[1001:]\n",
    "y = angl_data[\"sentiment\"].values\n",
    "train_cross = angl_data[\"tweet\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y).astype('int32')\n",
    "Y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y[:1000]\n",
    "y_test = Y[1001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         analyzer='word',\n",
    "                         max_df=0.9, \n",
    "                         min_df=5\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = tf_idf.fit(train_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_idf_vec = tf_idf_model.transform(train)\n",
    "test_tf_idf_vec = tf_idf_model.transform(test)\n",
    "train_cross_vec = tf_idf_model.transform(train_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 759)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_idf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 759)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf_idf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 4)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "#model.add(Dense(461, input_dim=461))\n",
    "model2.add(Dense(512, input_dim=759, activation=\"relu\"))\n",
    "#model1.add(Dense(256, activation=\"relu\"))\n",
    "#model1.add(Dense(512, activation=\"relu\"))\n",
    "#model.add(Dense(64, activation=\"relu\"))\n",
    "model2.add(Dense(4,  activation=\"softmax\"))\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=0.000001, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 205 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4272 - acc: 0.7820 - val_loss: 0.4626 - val_acc: 0.7537\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4258 - acc: 0.7785 - val_loss: 0.4617 - val_acc: 0.7561\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4244 - acc: 0.7807 - val_loss: 0.4609 - val_acc: 0.7561\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4231 - acc: 0.7855 - val_loss: 0.4603 - val_acc: 0.7549\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4217 - acc: 0.7872 - val_loss: 0.4597 - val_acc: 0.7549\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4204 - acc: 0.7880 - val_loss: 0.4591 - val_acc: 0.7549\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4191 - acc: 0.7862 - val_loss: 0.4584 - val_acc: 0.7537\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4177 - acc: 0.7955 - val_loss: 0.4578 - val_acc: 0.7537\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4164 - acc: 0.7928 - val_loss: 0.4572 - val_acc: 0.7537\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4150 - acc: 0.7892 - val_loss: 0.4566 - val_acc: 0.7707\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4138 - acc: 0.8008 - val_loss: 0.4562 - val_acc: 0.7671\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4125 - acc: 0.7985 - val_loss: 0.4556 - val_acc: 0.7720\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4111 - acc: 0.8010 - val_loss: 0.4551 - val_acc: 0.7744\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4096 - acc: 0.8090 - val_loss: 0.4549 - val_acc: 0.7622\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4083 - acc: 0.8005 - val_loss: 0.4544 - val_acc: 0.7707\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4069 - acc: 0.8040 - val_loss: 0.4536 - val_acc: 0.7707\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4054 - acc: 0.8058 - val_loss: 0.4531 - val_acc: 0.7756\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4040 - acc: 0.8060 - val_loss: 0.4525 - val_acc: 0.7817\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4026 - acc: 0.8113 - val_loss: 0.4523 - val_acc: 0.7756\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4012 - acc: 0.8125 - val_loss: 0.4518 - val_acc: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f100773ff98>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_tf_idf_vec, y_train,  batch_size = 5, epochs=20, verbose=1, validation_data = (test_tf_idf_vec, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_data = pd.read_csv(\"Roma_Franzthus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_data = french_data.drop(list(french_data[french_data[\"sentiment\"] == 99].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = french_data[\"tweet\"].values[:1500]\n",
    "test = french_data[\"tweet\"].values[1501:]\n",
    "y = french_data[\"sentiment\"].values\n",
    "train_cross = french_data[\"tweet\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = np.array(y).astype('int32')\n",
    "Y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y[:1500]\n",
    "y_test = Y[1501:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         analyzer='word',\n",
    "                         max_df=0.9, \n",
    "                         min_df=5\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = tf_idf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_idf_vec = tf_idf_model.transform(train)\n",
    "test_tf_idf_vec = tf_idf_model.transform(test)\n",
    "train_cross_vec = tf_idf_model.transform(train_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 3)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 741)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_idf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 741)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tf_idf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 3)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "#model.add(Dense(461, input_dim=461))\n",
    "model3.add(Dense(512, input_dim=741, activation=\"relu\"))\n",
    "#model.add(Dense(256, activation=\"relu\"))\n",
    "#model1.add(Dense(512, activation=\"relu\"))\n",
    "#model.add(Dense(64, activation=\"relu\"))\n",
    "model3.add(Dense(3,  activation=\"softmax\"))\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=0.000001, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 382 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5940 - acc: 0.6713 - val_loss: 0.5035 - val_acc: 0.7688\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5619 - acc: 0.7329 - val_loss: 0.4670 - val_acc: 0.8482\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5564 - acc: 0.7320 - val_loss: 0.4540 - val_acc: 0.8482\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5543 - acc: 0.7320 - val_loss: 0.4553 - val_acc: 0.8482\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5523 - acc: 0.7320 - val_loss: 0.4526 - val_acc: 0.8482\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5503 - acc: 0.7320 - val_loss: 0.4528 - val_acc: 0.8482\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5484 - acc: 0.7320 - val_loss: 0.4506 - val_acc: 0.8482\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5462 - acc: 0.7320 - val_loss: 0.4516 - val_acc: 0.8482\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5443 - acc: 0.7320 - val_loss: 0.4490 - val_acc: 0.8482\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5421 - acc: 0.7320 - val_loss: 0.4492 - val_acc: 0.8482\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5399 - acc: 0.7327 - val_loss: 0.4491 - val_acc: 0.8482\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5376 - acc: 0.7353 - val_loss: 0.4482 - val_acc: 0.8482\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5352 - acc: 0.7369 - val_loss: 0.4454 - val_acc: 0.8482\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5328 - acc: 0.7384 - val_loss: 0.4462 - val_acc: 0.8482\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5304 - acc: 0.7389 - val_loss: 0.4427 - val_acc: 0.8482\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5278 - acc: 0.7400 - val_loss: 0.4405 - val_acc: 0.8482\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5250 - acc: 0.7422 - val_loss: 0.4371 - val_acc: 0.8482\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5220 - acc: 0.7416 - val_loss: 0.4439 - val_acc: 0.8534\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5193 - acc: 0.7473 - val_loss: 0.4340 - val_acc: 0.8499\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5165 - acc: 0.7471 - val_loss: 0.4318 - val_acc: 0.8508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10076861d0>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_tf_idf_vec, y_train,  batch_size = 5, epochs=20, verbose=1, validation_data = (test_tf_idf_vec, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_data = pd.read_csv(\"Roma_Nemets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_data = ger_data.drop(list(ger_data[ger_data[\"sentiment\"] == \"nan\"].index))\n",
    "ger_data = ger_data.drop(list(ger_data[ger_data[\"sentiment\"] == \"mixed\"].index))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ger_data[\"tweet\"].values[:4500]\n",
    "test = ger_data[\"tweet\"].values[4501:]\n",
    "y = ger_data[\"sentiment\"].values\n",
    "train_cross = ger_data[\"tweet\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y).astype('int32')\n",
    "Y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y[:4500]\n",
    "y_test = Y[4501:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         analyzer='word',\n",
    "                         max_df=0.9, \n",
    "                         min_df=5\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = tf_idf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_idf_vec = tf_idf_model.transform(train)\n",
    "test_tf_idf_vec = tf_idf_model.transform(test)\n",
    "train_cross_vec = tf_idf_model.transform(train_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 3)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 4530)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_idf_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "#model.add(Dense(461, input_dim=461))\n",
    "model3.add(Dense(1024, input_dim=4530, activation=\"relu\"))\n",
    "#model.add(Dense(256, activation=\"relu\"))\n",
    "#model1.add(Dense(512, activation=\"relu\"))\n",
    "#model.add(Dense(64, activation=\"relu\"))\n",
    "model3.add(Dense(3,  activation=\"softmax\"))\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=0.000001, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 2225 samples\n",
      "Epoch 1/5\n",
      "4500/4500 [==============================] - 12s 3ms/step - loss: 0.4373 - acc: 0.7882 - val_loss: 0.5093 - val_acc: 0.6947\n",
      "Epoch 2/5\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.4351 - acc: 0.7886 - val_loss: 0.5045 - val_acc: 0.6950\n",
      "Epoch 3/5\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.4328 - acc: 0.7890 - val_loss: 0.5094 - val_acc: 0.6950\n",
      "Epoch 4/5\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.4306 - acc: 0.7893 - val_loss: 0.5042 - val_acc: 0.6957\n",
      "Epoch 5/5\n",
      "4500/4500 [==============================] - 13s 3ms/step - loss: 0.4282 - acc: 0.7898 - val_loss: 0.4977 - val_acc: 0.6966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1005cdfa90>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_tf_idf_vec, y_train,  batch_size = 16, epochs=5, verbose=1, validation_data = (test_tf_idf_vec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
